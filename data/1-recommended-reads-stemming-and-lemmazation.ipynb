{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008102,
     "end_time": "2023-04-11T17:06:01.542092",
     "exception": false,
     "start_time": "2023-04-11T17:06:01.533990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![Logo](https://raw.githubusercontent.com/onursercanyilmaz/recommendedreads/main/images/recommendedreads_rectangle.png?token=GHSAT0AAAAAAB75L5AIJN35ELPMSG6AVDKSZBUBW7Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T08:35:46.756226Z",
     "iopub.status.busy": "2023-04-11T08:35:46.755857Z",
     "iopub.status.idle": "2023-04-11T08:35:49.145481Z",
     "shell.execute_reply": "2023-04-11T08:35:49.144486Z",
     "shell.execute_reply.started": "2023-04-11T08:35:46.756176Z"
    },
    "papermill": {
     "duration": 2.572135,
     "end_time": "2023-04-11T17:06:04.121419",
     "exception": false,
     "start_time": "2023-04-11T17:06:01.549284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/0-recommended-reads-clean-and-tokenize/__results__.html\n",
      "/kaggle/input/0-recommended-reads-clean-and-tokenize/tokenizeddata.csv\n",
      "/kaggle/input/0-recommended-reads-clean-and-tokenize/__notebook__.ipynb\n",
      "/kaggle/input/0-recommended-reads-clean-and-tokenize/__output__.json\n",
      "/kaggle/input/0-recommended-reads-clean-and-tokenize/custom.css\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import spacy\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T08:35:49.147978Z",
     "iopub.status.busy": "2023-04-11T08:35:49.147648Z",
     "iopub.status.idle": "2023-04-11T08:35:50.443360Z",
     "shell.execute_reply": "2023-04-11T08:35:50.442515Z",
     "shell.execute_reply.started": "2023-04-11T08:35:49.147931Z"
    },
    "papermill": {
     "duration": 1.482219,
     "end_time": "2023-04-11T17:06:05.611805",
     "exception": false,
     "start_time": "2023-04-11T17:06:04.129586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/0-recommended-reads-clean-and-tokenize/tokenizeddata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T08:35:50.445530Z",
     "iopub.status.busy": "2023-04-11T08:35:50.445081Z",
     "iopub.status.idle": "2023-04-11T08:35:53.153541Z",
     "shell.execute_reply": "2023-04-11T08:35:53.152497Z",
     "shell.execute_reply.started": "2023-04-11T08:35:50.445460Z"
    },
    "papermill": {
     "duration": 2.710697,
     "end_time": "2023-04-11T17:06:08.330564",
     "exception": false,
     "start_time": "2023-04-11T17:06:05.619867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['tokenizeddata'] = df['tokenizeddata'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T08:35:53.156404Z",
     "iopub.status.busy": "2023-04-11T08:35:53.156023Z",
     "iopub.status.idle": "2023-04-11T08:35:53.167498Z",
     "shell.execute_reply": "2023-04-11T08:35:53.166534Z",
     "shell.execute_reply.started": "2023-04-11T08:35:53.156323Z"
    },
    "papermill": {
     "duration": 0.024103,
     "end_time": "2023-04-11T17:06:08.362886",
     "exception": false,
     "start_time": "2023-04-11T17:06:08.338783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['obsidian',\n",
       " 'jennifer',\n",
       " 'l',\n",
       " 'armentrout',\n",
       " 'starting',\n",
       " 'suckswhen',\n",
       " 'moved',\n",
       " 'west',\n",
       " 'virginia',\n",
       " 'right',\n",
       " 'senior',\n",
       " 'year',\n",
       " 'id',\n",
       " 'pretty',\n",
       " 'much',\n",
       " 'resigned',\n",
       " 'thick',\n",
       " 'accents',\n",
       " 'dodgy',\n",
       " 'internet',\n",
       " 'access',\n",
       " 'whole',\n",
       " 'lot',\n",
       " 'boring',\n",
       " 'spotted',\n",
       " 'hot',\n",
       " 'neighbor',\n",
       " 'looming',\n",
       " 'height',\n",
       " 'eerie',\n",
       " 'green',\n",
       " 'eyes',\n",
       " 'things',\n",
       " 'looking',\n",
       " 'upand',\n",
       " 'opened',\n",
       " 'mouthdaemon',\n",
       " 'infuriating',\n",
       " 'arrogant',\n",
       " 'stabworthy',\n",
       " 'get',\n",
       " 'along',\n",
       " 'stranger',\n",
       " 'attacks',\n",
       " 'daemon',\n",
       " 'literally',\n",
       " 'freezes',\n",
       " 'time',\n",
       " 'wave',\n",
       " 'hand',\n",
       " 'well',\n",
       " 'something',\n",
       " 'unexpected',\n",
       " 'happens',\n",
       " 'hot',\n",
       " 'alien',\n",
       " 'living',\n",
       " 'next',\n",
       " 'door',\n",
       " 'marks',\n",
       " 'meyou',\n",
       " 'heard',\n",
       " 'alien',\n",
       " 'turns',\n",
       " 'daemon',\n",
       " 'sister',\n",
       " 'galaxy',\n",
       " 'enemies',\n",
       " 'wanting',\n",
       " 'steal',\n",
       " 'abilities',\n",
       " 'daemons',\n",
       " 'touch',\n",
       " 'lit',\n",
       " 'like',\n",
       " 'vegas',\n",
       " 'strip',\n",
       " 'way',\n",
       " 'im',\n",
       " 'getting',\n",
       " 'alive',\n",
       " 'sticking',\n",
       " 'close',\n",
       " 'daemon',\n",
       " 'alien',\n",
       " 'mojo',\n",
       " 'fades',\n",
       " 'dont',\n",
       " 'kill',\n",
       " 'first',\n",
       " 'young',\n",
       " 'adult',\n",
       " 'fantasy',\n",
       " 'paranormal',\n",
       " 'fantasy',\n",
       " 'romance',\n",
       " 'science',\n",
       " 'fiction',\n",
       " 'aliens',\n",
       " 'science',\n",
       " 'fiction',\n",
       " 'romance',\n",
       " 'paranormal',\n",
       " 'romance',\n",
       " 'fantasy',\n",
       " 'supernatural',\n",
       " 'fantasy',\n",
       " 'urban',\n",
       " 'fantasy',\n",
       " 'fiction',\n",
       " 'aliens']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenizeddata'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T08:35:53.170399Z",
     "iopub.status.busy": "2023-04-11T08:35:53.170066Z",
     "iopub.status.idle": "2023-04-11T08:35:54.005310Z",
     "shell.execute_reply": "2023-04-11T08:35:54.004495Z",
     "shell.execute_reply.started": "2023-04-11T08:35:53.170343Z"
    },
    "papermill": {
     "duration": 0.819972,
     "end_time": "2023-04-11T17:06:09.191269",
     "exception": false,
     "start_time": "2023-04-11T17:06:08.371297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def stem_and_lemma(tokens):\n",
    "    stemmed_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        stem = stemmer.stem(token)\n",
    "        stemmed_tokens.append(stem)\n",
    "\n",
    "\n",
    "    stemmed_tokens_spacy = []\n",
    "    for token in stemmed_tokens:\n",
    "        doc = nlp(token)\n",
    "        stem = doc[0].lemma_\n",
    "        stemmed_tokens_spacy.append(stem)\n",
    "    lemmatized_tokens = []\n",
    "\n",
    "    for token, stem in zip(tokens, stemmed_tokens_spacy):\n",
    "        pos = pos_tag([token])[0][1]\n",
    "        if pos.startswith('V'):  # verbs start with 'V' in the POS tags\n",
    "            lemma = lemmatizer.lemmatize(stem, pos='v')  # specify 'v' as the POS for verbs\n",
    "        elif pos.startswith('N'):  # nouns start with 'N' in the POS tags\n",
    "            lemma = lemmatizer.lemmatize(stem, pos='n')  # specify 'n' as the POS for nouns\n",
    "        elif pos.startswith('R'):  # adverbs start with 'R' in the POS tags\n",
    "            lemma = lemmatizer.lemmatize(stem, pos='r')  # specify 'r' as the POS for adverbs\n",
    "        elif pos.startswith('J'):  # adjectives start with 'J' in the POS tags\n",
    "            lemma = lemmatizer.lemmatize(stem, pos='a')  # specify 'a' as the POS for adjectives\n",
    "        else:\n",
    "            lemma = lemmatizer.lemmatize(stem)\n",
    "        lemmatized_tokens.append(lemma)\n",
    "\n",
    "    return lemmatized_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T08:35:54.007452Z",
     "iopub.status.busy": "2023-04-11T08:35:54.006892Z",
     "iopub.status.idle": "2023-04-11T11:54:16.166805Z",
     "shell.execute_reply": "2023-04-11T11:54:16.165591Z",
     "shell.execute_reply.started": "2023-04-11T08:35:54.007404Z"
    },
    "papermill": {
     "duration": 12527.300908,
     "end_time": "2023-04-11T20:34:56.500997",
     "exception": false,
     "start_time": "2023-04-11T17:06:09.200089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['tokenizeddata'] = df['tokenizeddata'].apply(lambda x: stem_and_lemma(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T11:54:16.169851Z",
     "iopub.status.busy": "2023-04-11T11:54:16.169479Z",
     "iopub.status.idle": "2023-04-11T11:54:17.906289Z",
     "shell.execute_reply": "2023-04-11T11:54:17.905152Z",
     "shell.execute_reply.started": "2023-04-11T11:54:16.169790Z"
    },
    "papermill": {
     "duration": 1.579486,
     "end_time": "2023-04-11T20:34:58.089393",
     "exception": false,
     "start_time": "2023-04-11T20:34:56.509907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"stemmedandlemmatizeddata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.007803,
     "end_time": "2023-04-11T20:34:58.105954",
     "exception": false,
     "start_time": "2023-04-11T20:34:58.098151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 12542.043126,
   "end_time": "2023-04-11T20:34:59.224147",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-11T17:05:57.181021",
   "version": "1.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

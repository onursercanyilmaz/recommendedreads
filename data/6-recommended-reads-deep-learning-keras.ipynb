{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec151a4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-10T17:31:41.779907Z",
     "iopub.status.busy": "2023-05-10T17:31:41.779538Z",
     "iopub.status.idle": "2023-05-10T17:31:41.812756Z",
     "shell.execute_reply": "2023-05-10T17:31:41.811750Z"
    },
    "papermill": {
     "duration": 0.040923,
     "end_time": "2023-05-10T17:31:41.815747",
     "exception": false,
     "start_time": "2023-05-10T17:31:41.774824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/googlenewsvectors/GoogleNews-vectors-negative300.bin\n",
      "/kaggle/input/2-recommended-reads-conversion-of-data-to-num/__results__.html\n",
      "/kaggle/input/2-recommended-reads-conversion-of-data-to-num/vectorizedData.csv\n",
      "/kaggle/input/2-recommended-reads-conversion-of-data-to-num/__notebook__.ipynb\n",
      "/kaggle/input/2-recommended-reads-conversion-of-data-to-num/__output__.json\n",
      "/kaggle/input/2-recommended-reads-conversion-of-data-to-num/custom.css\n",
      "/kaggle/input/2-recommended-reads-conversion-of-data-to-num/__results___files/__results___9_0.png\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2c422d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T17:31:41.825183Z",
     "iopub.status.busy": "2023-05-10T17:31:41.824801Z",
     "iopub.status.idle": "2023-05-10T17:35:54.335510Z",
     "shell.execute_reply": "2023-05-10T17:35:54.334272Z"
    },
    "papermill": {
     "duration": 252.661523,
     "end_time": "2023-05-10T17:35:54.482075",
     "exception": false,
     "start_time": "2023-05-10T17:31:41.820552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "276/276 [==============================] - 4s 8ms/step - loss: 53.6088 - accuracy: 0.1079 - val_loss: 2.4653 - val_accuracy: 0.1066\n",
      "Epoch 2/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4605 - accuracy: 0.1094 - val_loss: 2.4547 - val_accuracy: 0.1066\n",
      "Epoch 3/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4531 - accuracy: 0.1134 - val_loss: 2.4493 - val_accuracy: 0.1066\n",
      "Epoch 4/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4496 - accuracy: 0.1104 - val_loss: 2.4467 - val_accuracy: 0.1066\n",
      "Epoch 5/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4479 - accuracy: 0.1134 - val_loss: 2.4453 - val_accuracy: 0.1066\n",
      "Epoch 6/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4471 - accuracy: 0.1134 - val_loss: 2.4446 - val_accuracy: 0.1066\n",
      "Epoch 7/50\n",
      "276/276 [==============================] - 2s 7ms/step - loss: 2.4467 - accuracy: 0.1134 - val_loss: 2.4442 - val_accuracy: 0.1066\n",
      "Epoch 8/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4464 - accuracy: 0.1083 - val_loss: 2.4439 - val_accuracy: 0.1066\n",
      "Epoch 9/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4463 - accuracy: 0.1134 - val_loss: 2.4438 - val_accuracy: 0.1066\n",
      "Epoch 10/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4463 - accuracy: 0.1134 - val_loss: 2.4438 - val_accuracy: 0.1066\n",
      "Epoch 11/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4463 - accuracy: 0.1134 - val_loss: 2.4438 - val_accuracy: 0.1066\n",
      "Epoch 12/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1126 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 13/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1112 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 14/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1134 - val_loss: 2.4435 - val_accuracy: 0.1066\n",
      "Epoch 15/50\n",
      "276/276 [==============================] - 2s 7ms/step - loss: 2.4463 - accuracy: 0.1134 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 16/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1122 - val_loss: 2.4435 - val_accuracy: 0.1066\n",
      "Epoch 17/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1096 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 18/50\n",
      "276/276 [==============================] - 2s 7ms/step - loss: 2.4462 - accuracy: 0.1134 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 19/50\n",
      "276/276 [==============================] - 2s 7ms/step - loss: 2.4462 - accuracy: 0.1098 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 20/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4463 - accuracy: 0.1113 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 21/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1118 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 22/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1126 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 23/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1116 - val_loss: 2.4437 - val_accuracy: 0.1066\n",
      "Epoch 24/50\n",
      "276/276 [==============================] - 2s 7ms/step - loss: 2.4462 - accuracy: 0.1134 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 25/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1090 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 26/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1134 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 27/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1119 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 28/50\n",
      "276/276 [==============================] - 2s 7ms/step - loss: 2.4462 - accuracy: 0.1120 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 29/50\n",
      "276/276 [==============================] - 2s 7ms/step - loss: 2.4462 - accuracy: 0.1134 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 30/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1119 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 31/50\n",
      "276/276 [==============================] - 2s 7ms/step - loss: 2.4463 - accuracy: 0.1105 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 32/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1134 - val_loss: 2.4435 - val_accuracy: 0.1066\n",
      "Epoch 33/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1134 - val_loss: 2.4434 - val_accuracy: 0.1066\n",
      "Epoch 34/50\n",
      "276/276 [==============================] - 2s 7ms/step - loss: 2.4462 - accuracy: 0.1116 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 35/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1113 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 36/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1125 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 37/50\n",
      "276/276 [==============================] - 2s 7ms/step - loss: 2.4463 - accuracy: 0.1134 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 38/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4463 - accuracy: 0.1104 - val_loss: 2.4435 - val_accuracy: 0.1066\n",
      "Epoch 39/50\n",
      "276/276 [==============================] - 2s 7ms/step - loss: 2.4462 - accuracy: 0.1120 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 40/50\n",
      "276/276 [==============================] - 2s 7ms/step - loss: 2.4462 - accuracy: 0.1103 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 41/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1115 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 42/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1134 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 43/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1134 - val_loss: 2.4437 - val_accuracy: 0.1066\n",
      "Epoch 44/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1113 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 45/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1134 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 46/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1094 - val_loss: 2.4435 - val_accuracy: 0.1066\n",
      "Epoch 47/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1134 - val_loss: 2.4435 - val_accuracy: 0.1066\n",
      "Epoch 48/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1109 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 49/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4462 - accuracy: 0.1124 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 50/50\n",
      "276/276 [==============================] - 2s 6ms/step - loss: 2.4463 - accuracy: 0.1134 - val_loss: 2.4436 - val_accuracy: 0.1066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x793acac6f940>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "# Load the keyed vectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format('/kaggle/input/googlenewsvectors/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"/kaggle/input/2-recommended-reads-conversion-of-data-to-num/vectorizedData.csv\")\n",
    "data = data.drop_duplicates(subset=['booktitle', 'authorname'], keep='first')\n",
    "\n",
    "# Tokenize and vectorize the first book description\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['bookdescription'])\n",
    "sequences = tokenizer.texts_to_sequences(data['bookdescription'])\n",
    "word_index = tokenizer.word_index\n",
    "max_len = 100 # set the maximum length of the sequence\n",
    "X_desc = pad_sequences(sequences, maxlen=max_len)\n",
    "X_vec = np.zeros((len(data), word_vectors.vector_size))\n",
    "for i, desc in enumerate(data['bookdescription']):\n",
    "    words = desc.split()\n",
    "    vectors = [word_vectors[word] for word in words if word in word_vectors]\n",
    "    if vectors:\n",
    "        X_vec[i] = np.mean(vectors, axis=0)\n",
    "\n",
    "# Combine the tokenized and vectorized features\n",
    "X = np.concatenate((X_desc, X_vec), axis=1)\n",
    "\n",
    "# Encoding the type column\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data['type'])\n",
    "y = label_encoder.transform(data['type'])\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating and training the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(216, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, pd.get_dummies(y_train), epochs=50, batch_size=32, validation_data=(X_test, pd.get_dummies(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e023fcb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T17:35:54.763983Z",
     "iopub.status.busy": "2023-05-10T17:35:54.763592Z",
     "iopub.status.idle": "2023-05-10T17:46:46.173193Z",
     "shell.execute_reply": "2023-05-10T17:46:46.171085Z"
    },
    "papermill": {
     "duration": 651.554576,
     "end_time": "2023-05-10T17:46:46.176202",
     "exception": false,
     "start_time": "2023-05-10T17:35:54.621626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "276/276 [==============================] - 14s 48ms/step - loss: 538.8013 - accuracy: 0.0893 - val_loss: 294.2744 - val_accuracy: 0.0744\n",
      "Epoch 2/50\n",
      "276/276 [==============================] - 13s 47ms/step - loss: 279.6488 - accuracy: 0.0930 - val_loss: 195.4376 - val_accuracy: 0.0957\n",
      "Epoch 3/50\n",
      "276/276 [==============================] - 12s 43ms/step - loss: 194.0098 - accuracy: 0.0938 - val_loss: 162.2690 - val_accuracy: 0.0943\n",
      "Epoch 4/50\n",
      "276/276 [==============================] - 12s 43ms/step - loss: 167.2136 - accuracy: 0.0959 - val_loss: 168.7647 - val_accuracy: 0.0857\n",
      "Epoch 5/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 112.7976 - accuracy: 0.0912 - val_loss: 68.5728 - val_accuracy: 0.1020\n",
      "Epoch 6/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 64.4155 - accuracy: 0.0890 - val_loss: 24.3817 - val_accuracy: 0.1020\n",
      "Epoch 7/50\n",
      "276/276 [==============================] - 12s 42ms/step - loss: 5.7394 - accuracy: 0.1077 - val_loss: 2.4915 - val_accuracy: 0.1166\n",
      "Epoch 8/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4728 - accuracy: 0.1122 - val_loss: 2.4585 - val_accuracy: 0.1166\n",
      "Epoch 9/50\n",
      "276/276 [==============================] - 12s 42ms/step - loss: 2.4570 - accuracy: 0.1122 - val_loss: 2.4501 - val_accuracy: 0.1170\n",
      "Epoch 10/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4514 - accuracy: 0.1122 - val_loss: 2.4473 - val_accuracy: 0.1166\n",
      "Epoch 11/50\n",
      "276/276 [==============================] - 11s 42ms/step - loss: 2.4490 - accuracy: 0.1121 - val_loss: 2.4458 - val_accuracy: 0.1147\n",
      "Epoch 12/50\n",
      "276/276 [==============================] - 12s 43ms/step - loss: 2.4477 - accuracy: 0.1128 - val_loss: 2.4450 - val_accuracy: 0.1134\n",
      "Epoch 13/50\n",
      "276/276 [==============================] - 12s 42ms/step - loss: 2.4470 - accuracy: 0.1084 - val_loss: 2.4439 - val_accuracy: 0.1179\n",
      "Epoch 14/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4465 - accuracy: 0.1118 - val_loss: 2.4435 - val_accuracy: 0.1229\n",
      "Epoch 15/50\n",
      "276/276 [==============================] - 12s 42ms/step - loss: 2.4468 - accuracy: 0.1149 - val_loss: 2.4439 - val_accuracy: 0.1066\n",
      "Epoch 16/50\n",
      "276/276 [==============================] - 12s 42ms/step - loss: 2.4460 - accuracy: 0.1124 - val_loss: 2.4429 - val_accuracy: 0.1070\n",
      "Epoch 17/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4459 - accuracy: 0.1112 - val_loss: 2.4436 - val_accuracy: 0.1066\n",
      "Epoch 18/50\n",
      "276/276 [==============================] - 12s 42ms/step - loss: 2.4458 - accuracy: 0.1125 - val_loss: 2.4428 - val_accuracy: 0.1070\n",
      "Epoch 19/50\n",
      "276/276 [==============================] - 11s 42ms/step - loss: 2.4455 - accuracy: 0.1145 - val_loss: 2.4424 - val_accuracy: 0.1066\n",
      "Epoch 20/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4453 - accuracy: 0.1115 - val_loss: 2.4420 - val_accuracy: 0.1175\n",
      "Epoch 21/50\n",
      "276/276 [==============================] - 12s 44ms/step - loss: 2.4452 - accuracy: 0.1133 - val_loss: 2.4425 - val_accuracy: 0.1116\n",
      "Epoch 22/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4449 - accuracy: 0.1146 - val_loss: 2.4417 - val_accuracy: 0.1179\n",
      "Epoch 23/50\n",
      "276/276 [==============================] - 12s 42ms/step - loss: 2.4448 - accuracy: 0.1103 - val_loss: 2.4414 - val_accuracy: 0.1215\n",
      "Epoch 24/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4445 - accuracy: 0.1143 - val_loss: 2.4413 - val_accuracy: 0.1143\n",
      "Epoch 25/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4441 - accuracy: 0.1185 - val_loss: 2.4413 - val_accuracy: 0.1202\n",
      "Epoch 26/50\n",
      "276/276 [==============================] - 12s 43ms/step - loss: 2.4438 - accuracy: 0.1184 - val_loss: 2.4423 - val_accuracy: 0.1093\n",
      "Epoch 27/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4442 - accuracy: 0.1154 - val_loss: 2.4407 - val_accuracy: 0.1107\n",
      "Epoch 28/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4434 - accuracy: 0.1177 - val_loss: 2.4400 - val_accuracy: 0.1329\n",
      "Epoch 29/50\n",
      "276/276 [==============================] - 12s 44ms/step - loss: 2.4426 - accuracy: 0.1149 - val_loss: 2.4389 - val_accuracy: 0.1288\n",
      "Epoch 30/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4421 - accuracy: 0.1221 - val_loss: 2.4393 - val_accuracy: 0.1293\n",
      "Epoch 31/50\n",
      "276/276 [==============================] - 12s 42ms/step - loss: 2.5408 - accuracy: 0.1206 - val_loss: 2.4384 - val_accuracy: 0.1392\n",
      "Epoch 32/50\n",
      "276/276 [==============================] - 12s 43ms/step - loss: 2.4411 - accuracy: 0.1259 - val_loss: 2.4382 - val_accuracy: 0.1215\n",
      "Epoch 33/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4403 - accuracy: 0.1299 - val_loss: 2.4390 - val_accuracy: 0.1116\n",
      "Epoch 34/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4402 - accuracy: 0.1354 - val_loss: 2.4368 - val_accuracy: 0.1447\n",
      "Epoch 35/50\n",
      "276/276 [==============================] - 12s 43ms/step - loss: 2.4392 - accuracy: 0.1339 - val_loss: 2.4363 - val_accuracy: 0.1424\n",
      "Epoch 36/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4385 - accuracy: 0.1385 - val_loss: 2.4359 - val_accuracy: 0.1279\n",
      "Epoch 37/50\n",
      "276/276 [==============================] - 12s 43ms/step - loss: 2.4380 - accuracy: 0.1417 - val_loss: 2.4346 - val_accuracy: 0.1524\n",
      "Epoch 38/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4373 - accuracy: 0.1357 - val_loss: 2.4336 - val_accuracy: 0.1261\n",
      "Epoch 39/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4362 - accuracy: 0.1347 - val_loss: 2.4331 - val_accuracy: 0.1392\n",
      "Epoch 40/50\n",
      "276/276 [==============================] - 12s 44ms/step - loss: 2.4357 - accuracy: 0.1441 - val_loss: 2.4322 - val_accuracy: 0.1592\n",
      "Epoch 41/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4364 - accuracy: 0.1340 - val_loss: 2.4327 - val_accuracy: 0.1351\n",
      "Epoch 42/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4351 - accuracy: 0.1433 - val_loss: 2.4307 - val_accuracy: 0.1506\n",
      "Epoch 43/50\n",
      "276/276 [==============================] - 12s 44ms/step - loss: 2.4341 - accuracy: 0.1493 - val_loss: 2.4304 - val_accuracy: 0.1519\n",
      "Epoch 44/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4329 - accuracy: 0.1548 - val_loss: 2.4293 - val_accuracy: 0.1474\n",
      "Epoch 45/50\n",
      "276/276 [==============================] - 12s 43ms/step - loss: 2.4319 - accuracy: 0.1516 - val_loss: 2.4276 - val_accuracy: 0.1583\n",
      "Epoch 46/50\n",
      "276/276 [==============================] - 12s 42ms/step - loss: 2.5424 - accuracy: 0.1553 - val_loss: 2.4278 - val_accuracy: 0.1537\n",
      "Epoch 47/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4295 - accuracy: 0.1500 - val_loss: 2.4261 - val_accuracy: 0.1415\n",
      "Epoch 48/50\n",
      "276/276 [==============================] - 12s 44ms/step - loss: 2.4279 - accuracy: 0.1559 - val_loss: 2.4234 - val_accuracy: 0.1678\n",
      "Epoch 49/50\n",
      "276/276 [==============================] - 11s 42ms/step - loss: 2.4264 - accuracy: 0.1658 - val_loss: 2.4222 - val_accuracy: 0.1655\n",
      "Epoch 50/50\n",
      "276/276 [==============================] - 11s 41ms/step - loss: 2.4237 - accuracy: 0.1643 - val_loss: 2.4193 - val_accuracy: 0.1410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x793acc15b730>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, GlobalMaxPooling1D\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "# Load the keyed vectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format('/kaggle/input/googlenewsvectors/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"/kaggle/input/2-recommended-reads-conversion-of-data-to-num/vectorizedData.csv\")\n",
    "data = data.drop_duplicates(subset=['booktitle', 'authorname'], keep='first')\n",
    "\n",
    "# Tokenize and vectorize the first book description\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['bookdescription'])\n",
    "sequences = tokenizer.texts_to_sequences(data['bookdescription'])\n",
    "word_index = tokenizer.word_index\n",
    "max_len = 100 # set the maximum length of the sequence\n",
    "X_desc = pad_sequences(sequences, maxlen=max_len)\n",
    "X_vec = np.zeros((len(data), word_vectors.vector_size))\n",
    "for i, desc in enumerate(data['bookdescription']):\n",
    "    words = desc.split()\n",
    "    vectors = [word_vectors[word] for word in words if word in word_vectors]\n",
    "    if vectors:\n",
    "        X_vec[i] = np.mean(vectors, axis=0)\n",
    "\n",
    "# Combine the tokenized and vectorized features\n",
    "X = np.concatenate((X_desc, X_vec), axis=1)\n",
    "\n",
    "# Encoding the type column\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data['type'])\n",
    "y = label_encoder.transform(data['type'])\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating and training the model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(128, kernel_size=5, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train.reshape((len(X_train), X_train.shape[1], 1)), pd.get_dummies(y_train), epochs=50, batch_size=32, validation_data=(X_test.reshape((len(X_test), X_test.shape[1], 1)), pd.get_dummies(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f0f56",
   "metadata": {
    "papermill": {
     "duration": 0.803569,
     "end_time": "2023-05-10T17:46:47.784703",
     "exception": false,
     "start_time": "2023-05-10T17:46:46.981134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 923.522506,
   "end_time": "2023-05-10T17:46:51.885035",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-10T17:31:28.362529",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
